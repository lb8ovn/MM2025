{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men's regular season results: (190771, 8)\n",
      "Men's teams: (380, 4)\n",
      "Women's regular season results: (134961, 8)\n",
      "Women's teams: (378, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# == Load data ==\n",
    "# Replace \"...\" with actual filenames and paths\n",
    "m_reg = pd.read_csv(\"MRegularSeasonCompactResults.csv\")\n",
    "m_teams = pd.read_csv(\"MTeams.csv\")\n",
    "w_reg = pd.read_csv(\"WRegularSeasonCompactResults.csv\")\n",
    "w_teams = pd.read_csv(\"WTeams.csv\")\n",
    "\n",
    "print(f\"Men's regular season results: {m_reg.shape}\")\n",
    "print(f\"Men's teams: {m_teams.shape}\")\n",
    "print(f\"Women's regular season results: {w_reg.shape}\")\n",
    "print(f\"Women's teams: {w_teams.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  OppTeamID  ScoreDiff  HomeAwayIndicator  Label\n",
      "0    1228       1328         17                0.5      1\n",
      "1    1328       1228        -17                0.5      0\n",
      "2    1106       1354          7                1.0      1\n",
      "3    1354       1106         -7                0.0      0\n",
      "4    1112       1223          7                1.0      1\n",
      "   TeamID  OppTeamID  ScoreDiff  HomeAwayIndicator  Label\n",
      "0    3104       3202         50                1.0      1\n",
      "1    3202       3104        -50                0.0      0\n",
      "2    3163       3221         11                1.0      1\n",
      "3    3221       3163        -11                0.0      0\n",
      "4    3222       3261          7                1.0      1\n"
     ]
    }
   ],
   "source": [
    "def prepare_training_data(regular_season_results):\n",
    "    \"\"\"\n",
    "    Convert each game into two training examples:\n",
    "      - team_won (label=1)\n",
    "      - team_lost (label=0)\n",
    "    Returns a DataFrame that can be used to train a classifier.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "    \n",
    "    for index, row in regular_season_results.iterrows():\n",
    "        wteam = row['WTeamID']\n",
    "        lteam = row['LTeamID']\n",
    "        wscore = row['WScore']\n",
    "        lscore = row['LScore']\n",
    "        wloc = row['WLoc']  # 'H','A','N'\n",
    "        \n",
    "        # Example 1: Winner perspective\n",
    "        df_list.append({\n",
    "            'TeamID': wteam,\n",
    "            'OppTeamID': lteam,\n",
    "            'ScoreDiff': wscore - lscore,  # Should be positive\n",
    "            'HomeAwayIndicator': 1 if wloc=='H' else (0 if wloc=='A' else 0.5),\n",
    "            'Label': 1\n",
    "        })\n",
    "        \n",
    "        # Example 2: Loser perspective\n",
    "        df_list.append({\n",
    "            'TeamID': lteam,\n",
    "            'OppTeamID': wteam,\n",
    "            'ScoreDiff': lscore - wscore,  # Should be negative\n",
    "            'HomeAwayIndicator': 1 if wloc=='A' else (0 if wloc=='H' else 0.5),\n",
    "            'Label': 0\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(df_list)\n",
    "\n",
    "m_train = prepare_training_data(m_reg)\n",
    "w_train = prepare_training_data(w_reg)\n",
    "\n",
    "print(m_train.head())\n",
    "print(w_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Men's Brier Score (validation): 0.0000\n",
      "Women's Brier Score (validation): 0.0000\n"
     ]
    }
   ],
   "source": [
    "feature_cols = ['ScoreDiff', 'HomeAwayIndicator']\n",
    "\n",
    "# --- Men's model ---\n",
    "X_m = m_train[feature_cols]\n",
    "y_m = m_train['Label']\n",
    "\n",
    "X_m_train, X_m_val, y_m_train, y_m_val = train_test_split(X_m, y_m, test_size=0.2, random_state=42)\n",
    "model_m = LogisticRegression()\n",
    "model_m.fit(X_m_train, y_m_train)\n",
    "\n",
    "val_preds_m = model_m.predict_proba(X_m_val)[:,1]\n",
    "m_val_brier_score = np.mean((val_preds_m - y_m_val)**2)\n",
    "print(f\"Men's Brier Score (validation): {m_val_brier_score:.4f}\")\n",
    "\n",
    "# --- Women's model ---\n",
    "X_w = w_train[feature_cols]\n",
    "y_w = w_train['Label']\n",
    "\n",
    "X_w_train, X_w_val, y_w_train, y_w_val = train_test_split(X_w, y_w, test_size=0.2, random_state=42)\n",
    "model_w = LogisticRegression()\n",
    "model_w.fit(X_w_train, y_w_train)\n",
    "\n",
    "val_preds_w = model_w.predict_proba(X_w_val)[:,1]\n",
    "w_val_brier_score = np.mean((val_preds_w - y_w_val)**2)\n",
    "print(f\"Women's Brier Score (validation): {w_val_brier_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of men’s pairs: 72010\n",
      "Number of women’s pairs: 71253\n"
     ]
    }
   ],
   "source": [
    "# Get all men’s team IDs\n",
    "men_team_ids = sorted(m_teams['TeamID'].unique())\n",
    "# Get all women’s team IDs\n",
    "women_team_ids = sorted(w_teams['TeamID'].unique())\n",
    "\n",
    "# Cartesian product: all possible pairs for men\n",
    "men_pairs = []\n",
    "for t1, t2 in product(men_team_ids, men_team_ids):\n",
    "    if t1 < t2:\n",
    "        men_pairs.append((t1, t2))\n",
    "\n",
    "# Cartesian product: all possible pairs for women\n",
    "women_pairs = []\n",
    "for t1, t2 in product(women_team_ids, women_team_ids):\n",
    "    if t1 < t2:\n",
    "        women_pairs.append((t1, t2))\n",
    "\n",
    "print(f\"Number of men’s pairs: {len(men_pairs)}\")\n",
    "print(f\"Number of women’s pairs: {len(women_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that team 1101 beats 1102 = 0.501\n"
     ]
    }
   ],
   "source": [
    "def predict_matchup_probability(model, team1, team2):\n",
    "    \"\"\"\n",
    "    Using the logistic regression model, returns P(team1 beats team2).\n",
    "    For a real approach, you’d incorporate advanced rating features for both teams.\n",
    "    Here we pass ScoreDiff=0, Home/Away=0.5 (as if a neutral site).\n",
    "    \"\"\"\n",
    "    X_row = pd.DataFrame({\n",
    "        'ScoreDiff': [0], \n",
    "        'HomeAwayIndicator': [0.5]\n",
    "    })\n",
    "    prob = model.predict_proba(X_row)[:,1]\n",
    "    return prob[0]\n",
    "\n",
    "# Example usage:\n",
    "example_prob = predict_matchup_probability(model_m, men_team_ids[0], men_team_ids[1])\n",
    "print(f\"Probability that team {men_team_ids[0]} beats {men_team_ids[1]} = {example_prob:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID      Pred\n",
      "0  M_1101_1102  0.500561\n",
      "1  M_1101_1103  0.500561\n",
      "2  M_1101_1104  0.500561\n",
      "3  M_1101_1105  0.500561\n",
      "4  M_1101_1106  0.500561\n",
      "5  M_1101_1107  0.500561\n",
      "6  M_1101_1108  0.500561\n",
      "7  M_1101_1109  0.500561\n",
      "8  M_1101_1110  0.500561\n",
      "9  M_1101_1111  0.500561\n",
      "Total submission rows: 143263\n"
     ]
    }
   ],
   "source": [
    "submission_rows = []\n",
    "\n",
    "# --- Men's predictions ---\n",
    "for (t1, t2) in men_pairs:\n",
    "    prob_t1_wins = predict_matchup_probability(model_m, t1, t2)\n",
    "    row_id = f\"M_{t1}_{t2}\"  # or \"M_2025_{t1}_{t2}\", depending on the competition requirement\n",
    "    submission_rows.append({\n",
    "        'ID': row_id,\n",
    "        'Pred': prob_t1_wins\n",
    "    })\n",
    "\n",
    "# --- Women's predictions ---\n",
    "for (t1, t2) in women_pairs:\n",
    "    prob_t1_wins = predict_matchup_probability(model_w, t1, t2)\n",
    "    row_id = f\"W_{t1}_{t2}\"\n",
    "    submission_rows.append({\n",
    "        'ID': row_id,\n",
    "        'Pred': prob_t1_wins\n",
    "    })\n",
    "\n",
    "submission_df = pd.DataFrame(submission_rows)\n",
    "print(submission_df.head(10))\n",
    "print(\"Total submission rows:\", submission_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_df[['ID','Pred']].to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submission file created: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
